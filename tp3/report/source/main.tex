\documentclass{estilo}
\usepackage[spanish]{babel}
\usepackage{graphicx}
\usepackage{float}
\usepackage{amsmath}        % para los vectores columnas
\usepackage{amsfonts}       % para las negrita de pizarra
\usepackage{amssymb}        % para simbolos matematicos
\usepackage{hyperref}       % para utilizar referencias
\usepackage{multirow}       % para las tablas
\usepackage{dsfont}
\usepackage{listings}
\usepackage{xcolor}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}

\usepackage{enumitem,multicol,setspace}
\newcounter{subenum}[enumi] % para las multicolumnas
\renewcommand{\thesubenum}{\arabic{subenum}}
\usepackage[nomessages]{fp}
\FPeval\thecolwidth{round(1/4:4)}% Specify number of columns -> column width
\newcommand{\newitem}[1]{%
  \refstepcounter{subenum}%
  \parbox{\dimexpr\thecolwidth\linewidth-.5\columnsep}{%
    \makebox[\labelwidth][r]{(\thesubenum)\hspace*{\labelsep}}%
    #1}\hfill%
}

\usepackage{scalerel,stackengine} % para el sombrero
\stackMath
\newcommand\rhat[1]{%
\savestack{\tmpbox}{\stretchto{%
  \scaleto{%
    \scalerel*[\widthof{\ensuremath{#1}}]{\kern-.6pt\bigwedge\kern-.6pt}%
    {\rule[-\textheight/2]{1ex}{\textheight}}%WIDTH-LIMITED BIG WEDGE
  }{\textheight}% 
}{0.5ex}}%
\stackon[1pt]{#1}{\tmpbox}%
}
\parskip 1ex

\usepackage{mathtools}      % floor y ceil
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor} 

\usepackage[style=authoryear-comp]{biblatex}


\begin{document}
\maketitle

\justifying{
}

% \newpage
% \input{tex/consideraciones}
\newpage

\section{Problemas NP-Completos}

El problema consiste en encontrar el conjunto mínimo de jugadores que satisface con al menos un jugador todos los deseos de la prensa. Como datos de entrada tenemos los deseos de la prensa, en base a los cuales obtenemos los jugadores a considerar.


\subsection{Demostración que Hitting Set es un problema NP}

\subsubsection{Definición de problemas NP}
Los problemas NP son aquellos para los que existe un certificador eficiente, es decir, aquellos que se pueden validar en tiempo polinomial.

\subsubsection{Demostración}

\textbf{Introducción}

\hspace{0.5cm} Este problema consiste en determinar si, dado un conjunto \(A\) de \(n\) elementos, \(m\) subconjuntos \(B_1, B_2, ..., B_m\) de \(A\), y un número entero \(k\), existe un subconjunto \(C\) de \(A\) con \(|C| \leq k\) tal que \(C \cap B_i \neq \emptyset\) para cada \(i\) en el rango de \(1\) a \(m\), es decir, que el subconjunto $C$ contenga al menos un elemento de cada subconjunto $B_i$.

\hspace{0.5cm} La pertenencia a NP se demuestra que, dada una solución propuesta \(C\), es posible verificar en tiempo polinómico si cumple con las condiciones del problema. Esto implica verificar el tamaño de \(C\) para asegurarse de que \(|C| \leq k\), lo cual es un proceso constante, y verificar la intersección de \(C\) con cada \(B_i\), garantizando que \(C \cap B_i \neq \emptyset\) para cada \(i\), en tiempo polinómico.

\textbf{Verificación}

\hspace{0.5cm} Tenemos dos condiciones que corroborar:


\begin{itemize}
    \item \textit{Tamaño del conjunto:} Verificar que $|C| \leq k$.
    \item \textit{Intersección con cada $B_i$:} Verificar que $C \cap B_i \neq \emptyset$ para cada $i$ en el rango de $1$ a $m$.
\end{itemize}

\hspace{0.5cm} Para la verificación del tamaño del conjunto, la operación de comparación $|C| \leq k$ toma $O(k)$ pasos, ya que se itera sobre $C$ un máximo de $k$ veces y se rechaza la solución si al llegar a $k$ no ha finalizado la iteración, indicando que el conjunto supera los $k$ elementos. Como $k$ es constante, $O(k)$ puede expresarse como $O(1)$.

\hspace{0.5cm} Para la verificación de la intersección con cada $B_i$, se realiza una búsqueda o comparación de cada elemento de $C$ con los elementos de $B_i$. Dado que $|C| \leq k$ y $|B_i|$ está acotado por el tamaño de $A$, la búsqueda toma $O(k \cdot n)$ pasos y, como se tienen $m$ subconjuntos $B_i$, la verificación de cada intersección es $O(k \cdot n \cdot m)$. Como $k$ es constante, puede expresarse como $O(n \cdot m)$

\hspace{0.5cm} En total, el tiempo de verificación es de $O(1 + n \cdot m)$, equivalente a $O(n \cdot m)$, lo cual es polinómico. Por lo tanto, la verificación del Hitting-Set Problem ocurre en tiempo polinómico y, en consecuencia, el problema está en NP.


\subsection{Demostración que Hitting Set es un problema NP-Completo}

\subsubsection{Definición de problemas NP-completo}

\hspace{0.5cm} \(X \in \text{NP-Completo}\) \(\Leftrightarrow\) \(X \in \text{NP} \land \forall Y \in \text{NP} (Y \leq_p X)\).

Esto quiere decir que: Sabemos que un problema es NP-Completo si y solo si es un problema que está en NP y también sucede que para cualquier problema que está en NP se puede reducir polinomialmente a dicho problema NP-Completo.

\newpage
\subsubsection{Demostración}

Utilizaremos el problema de satisfacibilidad con cláusulas de 3 variables (3-SAT) como ejemplo de un problema NP-completo. Este problema plantea la pregunta de si, dada una expresión donde cada clausula contiene tres variables booleanas conectadas por operadores OR, es posible encontrar una asignación de verdad para las variables que satisfaga todas las cláusulas. Para demostrar que Hitting Set es un problema NP-Completo, podemos reducir polinómicamente 3-SAT a este problema.

Dada una instancia de 3-SAT, construimos una fórmula booleana \(F\) para Hitting-Set Problem de la siguiente manera:

\begin{itemize}
    \item Cada variable en \(F\) se convierte en un conjunto en el conjunto universal \(X\).
    \item Cada cláusula en \(F\) se convierte en un subconjunto en \(B_i\).
\end{itemize}


Entonces, para resolver SAT, necesitamos encontrar un conjunto \(C\) tal que \(|C| \leq k\) y \(C \cap B_i \neq \emptyset\) para cada cláusula \(B_i\) en \(F\).

Supongamos que tenemos la siguiente instancia de 3-SAT:

\[ F = (x_1 \lor x_2 \lor \neg x_3) \land (\neg x_1 \lor x_2 \lor x_3) \land (x_1 \lor \neg x_2 \lor \neg x_3) \]

Ahora, construimos la instancia correspondiente del \textit{Hitting-Set Problem} utilizando la reducción mencionada:

\begin{minipage}[t]{0.7\textwidth}
    \textbf{Conjunto universal:} \(X = \{x_1, \overline{x_1}, x_2, \overline{x_2}, x_3 \overline{x_3}\}\).

    \vspace{0.5cm}

    \textbf{Subconjuntos \(B_i\):}
    \begin{align*}
        B_1 & = \{x_1, x_2, \overline{x_3}\} \\
        B_2 & = \{\overline{x_1}, x_2, x_3\} \\
        B_3 & = \{x_1, \overline{x_2}, \overline{x_3}\}
    \end{align*}
\end{minipage}
\hfill
\begin{minipage}[t]{0.3\textwidth}
    \begin{tikzpicture}[baseline=(current bounding box.north)]
        % Conjunto universal X
        \node[circle, draw] (x_1) at (0,0) {$x_1$};
        \node[circle, draw] (x_2) at (1,0) {$x_2$};
        \node[circle, draw] (x_3) at (2,0) {$x_3$};
        
        % Subconjuntos B_i
        \node[ellipse, draw] (B1) at (0.5,-1.5) {$B_1$};
        \node[ellipse, draw] (B2) at (1.5,-1.5) {$B_2$};
        \node[ellipse, draw] (B3) at (2.5,-1.5) {$B_3$};
        
        % Arrows
        \draw[->] (B1) -- (x_1);
        \draw[->] (B1) -- (x_2);
        \draw[->, red] (B1) -- (x_3);
        
        \draw[->, red] (B2) -- (x_1);
        \draw[->] (B2) -- (x_2);
        \draw[->] (B2) -- (x_3);
        
        \draw[->,] (B3) -- (x_1);
        \draw[->, red] (B3) -- (x_2);
        \draw[->, red] (B3) -- (x_3);
    \end{tikzpicture}
\end{minipage} \\ \\

Entonces, para resolver el \textit{Hitting-Set Problem}, necesitamos encontrar un conjunto de elementos seleccionados \(C\) tal que \(|C| \leq k\) y \(C \cap B_i \neq \emptyset\) para cada \(B_i\) en \(F\).

Como $F$ está compuesto por tres variables y sus complementos, suponemos que $k = 3$, ya que una solución no puede contener una variable que es positiva y negativa al mismo tiempo. 

Un conjunto de elementos seleccionados posible podría ser \(C = \{x_1, x_2\}\):

\[ x_1 = \text{True}, \quad x_2 = \text{True}, \quad x_3 = \text{False} \]

Verificamos si esta asignación satisface todas las cláusulas de 3-SAT:

\[ B_1: (x_1 \lor x_2 \lor \neg x_3) = (\text{True} \lor \text{True} \lor \text{True}) = \text{True} \]
\[ B_2: (\neg x_1 \lor x_2 \lor x_3) = (\text{False} \lor \text{True} \lor \text{False}) = \text{True} \]
\[ B_3: (x_1 \lor \neg x_2 \lor \neg x_3) = (\text{True} \lor \text{False} \lor \text{True}) = \text{True} \]

La asignación satisface todas las cláusulas de 3-SAT \checkmark.

\newpage

A su vez, vemos que:
\begin{itemize}
    \item \textbf{Tamaño del conjunto:} \(|C| = 2 \leq 3\) (cumple con \(k = 3\)).
    \item \textbf{Intersección con cada \(B_i\):}
        \begin{align*}
            C \cap B_1 & = \{x_1\} \neq \emptyset \\
            C \cap B_2 & = \{x_2\} \neq \emptyset \\
            C \cap B_3 & = \{x_1\} \neq \emptyset \quad
        \end{align*}
\end{itemize}


Por lo tanto, \(C = \{x_1, x_2\}\) es un conjunto de elementos seleccionados válido para la instancia del \textit{Hitting-Set Problem}, pero dado que \textit{3-SAT} es un problema de decisión nos basta con saber que hay solución válida posible.

En resumen, hemos demostrado que el \textit{Hitting-Set Problem} está en NP y que es NP-Completo al mostrar una reducción polinómica desde \textit{3-SAT}.

\section{Algoritmo de Backtracking}

\subsection{Introducción}
El algoritmo consiste en explorar un espacio exponencial de soluciones al problema probando si agregando un jugador a la lista de jugadores convocados se logra satisfacer el Hitting Set Problem. Al ser esto una solución de fuerza bruta buscamos optimizar el algoritmo a través de varias condiciones de corte para evitar explorar soluciones que no resuelven el problema o son menos óptimas que una solución ya encontrada. 

Para asistir con estas optimizaciones decidimos representar el problema con una clase de manera que nos facilite guardar en el estado interno de la misma la mejor solución encontrada.

Se aplicaron las siguientes optimizaciones:
\begin{itemize}
\item{Como el algoritmo va probando las soluciones desde la menor cantidad de jugadores a la mayor pudimos hacer una optimización muy grande cortando la rama recursiva una vez que encontramos una solución menor a la almacenada para el problema (o cualquier solución valida en el caso de todavía no tener una).}

\item {Reducimos en cada llamado recursivo la lista de deseos con aquellos deseos que todavía quedan por satisfacer (excluyendo los deseos que ya tienen al menos un jugador que es parte de la solución actual)}

\item {Agregamos una lista con los jugadores descartados de manera que podamos detectar cuando algún deseo ya no se puede cumplir con los jugadores que quedan sin descartar.}

\end{itemize}

\subsection{Complejidad algorítmica}

La complejidad algorítmica es $O(2^n)$ ya que en el peor de los casos este algoritmo termina corriendo como su base de fuerza bruta, donde se prueban todas las combinaciones posibles de jugadores hasta encontrar una solución válida.

\newpage
\subsection{El algoritmo}
\begin{lstlisting}[language=Python]
def hitting_set_backtracking(deseos):
    return HittingSetBacktracking(deseos).buscar_solucion()

class HittingSetBacktracking():
    def __init__(self, deseos_prensa):
        self._solucion = None
        self._deseos_prensa = deseos_prensa
    
    def buscar_solucion(self):
        self._buscar_solucion(self._deseos_prensa, [], [])
        return list(self._solucion)

    def _buscar_solucion(self, deseos_pendientes, convocados, descartados):
        if not self._puede_ser_solucion_optima(convocados):
            return
            
        deseos_pendientes = _deseos_pendientes(deseos_pendientes, convocados)
        
        if not any(deseos_pendientes):
            self._marcar_mejor_solucion(convocados)
            return
    
        jugador = _jugador_siguiente(deseos_pendientes, descartados)
    
        if jugador == None:
            return
    
        if not _todos_los_deseos_se_pueden_cumplir(deseos_pendientes, descartados):
            return
                
        self._buscar_solucion(deseos_pendientes, convocados, [*descartados, jugador])
        self._buscar_solucion(deseos_pendientes, [*convocados, jugador], descartados)


    def _marcar_mejor_solucion(self, nueva_solucion):
        if self._puede_ser_solucion_optima(nueva_solucion):
            self._solucion = nueva_solucion
        
    def _puede_ser_solucion_optima(self, convocados):
        return not self._solucion or len(convocados) < len(self._solucion)

def _deseos_pendientes(deseos_prensa, convocados):
    deseos_restantes = []

    for deseo in deseos_prensa:
        cumplido = any(filter(lambda jugador: jugador in deseo, convocados))
        
        if not cumplido:
            deseos_restantes.append(deseo)
    
    return deseos_restantes

def _jugador_siguiente(deseos_pendientes, descartados):
    for deseo in deseos_pendientes:
        for jugador in deseo:
            if jugador in descartados:
                continue
            return jugador
    return None
    
def _todos_los_deseos_se_pueden_cumplir(deseos_prensa, descartados):
    for deseo in deseos_prensa:
        if any(filter(lambda jugador: not jugador in descartados, deseo)):
            continue
        return False
    return True

\end{lstlisting}

\newpage
\section{Algoritmo de programación lineal entera}

\subsection{Introducción}

Este algoritmo hace uso de la biblioteca PuLP de Python para resolver el problema mediante Programación Lineal. Consiste en definir qué problema debe resolver el modelo y cuáles son sus restricciones a través de ecuaciones matemáticas.

Para comenzar, se definen las variables de decisión creando un diccionario $x$ con los jugadores (obtenidos a partir de los deseos) como variables binarias utilizando 1s y 0s para representar si un jugador ( $x[jugador]$ ) es convocado o no respectivamente.

Después, se define el problema de programación lineal entera cuya función objetivo busca minimizar la suma de las variables $x$ para así minimizar el tamaño del conjunto de los jugadores convocados. Agregando, por cada deseo, una restricción donde la suma de las variables $x$ correspondientes a los jugadores del deseo debe ser mayor o igual a 1, asegurando que al menos un jugador de cada conjunto sea convocado.

Una vez terminado de definir el modelo, se utiliza el método \texttt{solve()} para ejecutar el algoritmo de programación lineal y obtener la solución óptima del modelo, permitiendo, luego, obtener la lista de jugadores convocados a través de indexar las variables $x$ que tienen un valor de 1 en la solución obtenida dentro de la lista de jugadores obtenida al principio.


\subsection{El algoritmo}

\begin{lstlisting}[language=Python]
from pulp import LpMinimize, LpProblem, LpVariable, lpSum

def hitting_set_programacion_lineal(deseos):
    deseos = [set(deseo) for deseo in deseos]

    jugadores = set.union(*deseos)
    x = LpVariable.dicts('x', jugadores, cat='Binary')
    
    hitting_set = LpProblem("HittingSet", LpMinimize)
    hitting_set += lpSum(x[jugador] for jugador in jugadores)
    for deseo in deseos:
        hitting_set += lpSum(x[jugador] for jugador in deseo) >= 1

    hitting_set.solve()
    convocados = [jugador for jugador in jugadores if x[jugador].value() == 1]
    return convocados
\end{lstlisting}

\newpage

\section{Algoritmo de aproximación Bilardo}

\subsection{Introducción}

Este algoritmo es una modificación del algoritmo anterior buscando obtener una aproximación en vez de una solución óptima utilizando valores reales en vez de enteros, permitiendo que se calcule la probabilidad de que el jugador participe en una solución.

Finalmente, decide si el jugador se elige o no en base a si su valor de participación se encuentra entre $1/b$  y 1 (donde $b = \text{La cantidad de jugadores del deseo más grande)}$.

\subsection{Análisis de la aproximación}

Sea $I$ una instancia cualquiera del Hitting-Set Problem, y $z(I)$ una solución óptima $S$ para dicha instancia, y sea $A(I)$ la solución aproximada $S^*$, se define $\frac{A(I)}{z(I)} \leq r(A)$ para todas las instancias posibles.

Supongamos que la elección de cada jugador $x_i$ tiene un costo $w_i$. Necesitamos minimizar $w(S) = \sum_{i \in S} w_i$.

Por cada deseo de prensa, tenemos
\[\sum w_j x_j \ge 1 \forall x_j \in B_i \quad\quad\quad \text{y} \quad\quad\quad 0 \le x_i \le 1, i \in S\]
Si tomamos como parte de la solución todo $x_i \ge \frac{1}{b}$, entonces:
\[w(S^*) = \sum_{i} w_i x_i^* \ge \sum_{i \in S} w_i x_i^* \ge \frac{1}{b} \sum_{i \in S} w_i = \frac{1}{b} w(S)\]
\[b \cdot w(S^*) \ge w(S)\]
\[b \cdot w(A(I)) \ge w(z(I))\]
La solución aproximada $A(I)$ es como mucho $b$ veces más grande que la solución óptima $z(I)$.
\[\frac{A(I)}{z(I)}\le \frac{b \cdot z(I)}{z(I)} = b = r(A)\]
    
Se puede encontrar el resultado de las pruebas empíricas realizadas para corroborar esta cota en la Página 14 de este mismo informe.
\subsection{El algoritmo}

\begin{lstlisting}[language=Python]
from pulp import LpMinimize, LpProblem, LpVariable, lpSum

def hitting_set_aproximacion_bilardo(deseos):
    deseos = [set(deseo) for deseo in deseos]
    
    b = max(len(deseo) for deseo in deseos)
    jugadores = set.union(*deseos)
    x = LpVariable.dict("x", jugadores, lowBound=0, upBound=1, cat='Continuous')
    
    hitting_set_aproximado = LpProblem(name="HittingSetAproximado", sense=LpMinimize)
    hitting_set_aproximado += lpSum(x[jugador] for jugador in jugadores)
    for deseo in deseos:
        hitting_set_aproximado += lpSum(x[jugador] for jugador in deseo) >= 1
        
    hitting_set_aproximado.solve()
    convocados = [jugador for jugador in jugadores if x[jugador].value() >= 1/b]
    return convocados
\end{lstlisting}



\newpage

\section{Algoritmo Greedy}

\subsection{Introducción}

Este algoritmo aproxima el resultado eligiendo en cada iteración al jugador más deseado (el que más se repite entre todos los deseos aún sin cumplir), de manera que se logra satisfacer siempre la mayor cantidad de deseos posibles en cada iteración.

\subsection{Análisis de la aproximación}

Cada vez que se busca al jugador más deseado entre los deseos restantes, se esta eligiendo al jugador que tiene más probabilidades de pertenecer a la solución. Sin embargo, pueden haber pequeños deseos que tengan jugadores pocos frecuentes por lo que son más difíciles de satisfacer.

Por ejemplo. si nuestros deseos son: \{\{1,2\}, \{1,2\}, \{1,3\}, \{1,3\}, \{2\}, \{3\}\}
Podemos ver que el 1 es el que más se repite (4 veces) y será el primero en ser seleccionado.
Esto nos dejará los deseos {{2}, {3}} sin cumplir, por lo que necesitaremos tomar todavía 2 números más, por lo que el Greedy nos quedará de tamaño 3. Podemos comprobar fácilmente que una solución óptima habría sido {2,3}.

Lo mismo sucedería en el caso que contemos con deseos con la siguiente estructura:
\[\{\]
\[\{1,2\}, \{1,2\}, \{1,3\}, \{1,3\}, \{2,4\}, \{3,5\},\]
\[\{6,7\}, \{6,7\}, \{6,8\}, \{6,8\}, \{7,9\}, \{8,10\},\]
\[\{11,12\}, \{11,12\}, \{11,13\}, \{11,13\}, \{12,14\}, \{13,15\},\]
\[\}

El resultado del algoritmo Greedy nos devuelve: \{1,6,11,2,3,7,8,12,13\} (9 jugadores), mientras una solución óptima obtenemos \{2,3,7,8,12,13\} (6 jugadores).

Para empezar a acotar un poco nuestra aproximación sabemos que la solución aproximada $S^* \subseteq A$, por lo tanto, $|S^*| \le n$. 

Como el universo de jugadores A podría ser infinito, podemos definir un subconjunto $D$ formado por aquellos jugadores que se encuentran en algún deseo de la prensa  ($D = \{x_i \in A / x_i \in B_i\})$. Como la solución no puede contener jugadores que no sean deseados, podríamos acotar mejor la solución a $|S^*| \le |D|$.

También, la solución aproximada buscará satisfacer la mayor cantidad de deseos, por lo que en el peor de los casos, tomará un jugador de cada $B_i$. De esta manera, $|S^*| \le m$.

Podemos concluir que, dado que $|S^*| \le |D|$ y $|S^*| \le m$, la solución aproximada puede alcanzar un tamaño máximo igual al mínimo entre la cantidad de jugadores deseados y la cantidad de deseos. De esta manera, $|S| \le |S^*| \le min(|D|, m)$

Se puede encontrar el resultado de las pruebas empíricas realizadas para corroborar esta cota en la Página 15 de este mismo informe.
\subsection{Complejidad algorítmica}

La complejidad algorítmica es $O(m^2 * n)$ porque en el peor de los casos se itera dos veces sobre los deseos de prensa, es decir, en el caso de que en cada iteración solo se cumpla un deseo se van a realizar $m$ iteraciones. Dentro de las cuales se itera por todos los deseos restantes y por cada deseo se itera hasta por $n$ jugadores buscando el que mas deseos cumpla sumando $O(n)$ a la complejidad.

\newpage
\subsection{El algoritmo}

\begin{lstlisting}[language=Python]
def hitting_set_greedy(deseos_prensa):
    convocados = []

    while len(deseos_prensa) > 0:
        cant_jugadores = {}
        max = None
        
        for deseo in deseos_prensa:
            for jugador in deseo:
                cant_jugadores[jugador] = cant_jugadores.get(jugador, 0) + 1
                if not max or cant_jugadores[jugador] > cant_jugadores[max]:
                    max = jugador
                    
        convocados.append(max)
        deseos_prensa = _deseos_restantes(deseos_prensa, convocados)
    return convocados
\end{lstlisting}

\newpage

\section{Mediciones}
\subsection{Metodología}

Creamos diferentes sets de datos utilizando el notebook \texttt{notebooks/Generador de archivos.ipynb}. Los datos generados se encuentran en la misma carpeta como archivos de texto \texttt{.txt}.

Estos sets de datos nos permitieron realizar las mediciones de los tiempos de ejecución, con su análisis y grafos. Esto se puede encontrar en el el archivo \texttt{notebooks/Algoritmos.ipynb}.

\subsection{Resultados}

\begin{center}
\includegraphics[width=0.7\textwidth]{img/tiempo_backtracking.png}

Podemos observar que, a medida que se va aumentando la cantidad de deseos, el tiempo de ejecución del algoritmo de Backtracking aumenta exponencialmente.
\end{center}

\newpage
\begin{center}
\includegraphics[width=0.7\textwidth]{img/tiempo_pl.png}

Podemos observar que, la curva con el algoritmo con Programación Lineal es significativamente más gradual que en comparación con la curva del algoritmo de Backtracking.
\end{center}

\begin{center}
\includegraphics[width=0.7\textwidth]{img/backtracking_vs_pl.png}

Si comparamos los resultados de evaluar ambos algoritmos con los mismos sets de datos, observamos que el algoritmo de Programación Lineal se desempeña mejor que el algoritmo de Backtracking, el cual con pocos sets de datos aumenta exponencialmente sus tiempos de ejecución.
\end{center}

\begin{center}
\includegraphics[width=0.7\textwidth]{img/tiempo_bilardo.png}

Se puede observar que el algoritmo de aproximación Bilardo reduce significativamente los tiempos de ejecución, a cambio de obtener una solución que puede diferir bastante con la solución óptima.
\end{center}

\begin{center}
\includegraphics[width=0.7\textwidth]{img/tiempo_greedy.png}

Al igual que con el anterior con este algoritmo de aproximación sucede que, se reduce significativamente el tiempo de ejecución a cambio de obtener una solución que puede diferir de la solución óptima.
\end{center}

\begin{center}
\includegraphics[width=0.7\textwidth]{img/bilardo_vs_greedy_1.png}

Podemos observar como los diferentes algoritmos de aproximación difieren en su complejidad, mostrando que el algoritmo Greedy tiene un tiempo de ejecución menor al algoritmo de Bilardo según la cantidad de deseos.
\end{center}

\begin{center}
\includegraphics[width=0.7\textwidth]{img/bilardo_vs_greedy_2.png}

Vemos que para los datos utilizados el algoritmo de Bilardo consistentemente devuelve más jugadores en su resultado comparado con el algoritmo Greedy, por lo tanto, pareciera ser mas óptimo este último.
\end{center}

\newpage
\begin{center}
\includegraphics[width=0.7\textwidth]{img/LPvsBilardo_cota1.png}

Podemos observar el gráfico de las pruebas de volúmenes realizadas para corroborar empíricamente la cota calculada y mencionada en la sección correspondiente al algoritmo de Aproximación de Bilardo, donde b es la cantidad de jugadores del deseo mas grande y r es la división entre el tiempo de aproximar el resultado y calcularlo por programación lineal.
\end{center}

\begin{center}
\includegraphics[width=0.7\textwidth]{img/LPvsBilardo_cota2.png}

En este gráfico podemos observar la Distancia entre la cota y la diferencia de aproximación de una manera mas directa, corroborando que en ninguna situación pasa a ser negativa (caso en el que se estaría superando la cota)
\end{center}

\newpage
\begin{center}
\includegraphics[width=0.7\textwidth]{img/LPvsGreedy_cota1.png}

Podemos observar el gráfico de las pruebas de volúmenes realizadas para corroborar empíricamente la cota calculada y mencionada en la sección correspondiente al algoritmo de Aproximación Greedy, donde $b$ es el mínimo entre la cantidad de jugadores deseados y la cantidad de deseos de prensa y r es la división entre el tiempo de aproximar el resultado y calcularlo por programación lineal
\end{center}

\begin{center}
\includegraphics[width=0.7\textwidth]{img/LPvsGreedy_cota2.png}

En este gráfico podemos observar la Distancia entre la cota y la diferencia de aproximación de una manera mas directa, corroborando que en ninguna situación pasa a ser negativa (caso en el que se estaría superando la cota)
\end{center}

\newpage
\section{Conclusiones}

Podemos concluir que el algoritmo de Programación Lineal nos permitió encontrar una solución óptima evitando explorar un espacio exponencial de soluciones como se hace con el algoritmo de Backtracking, por lo cuál, gracias a esta metodología pudimos reducir significativamente los tiempos de ejecución del algoritmo.

También encontramos que el algoritmo de aproximación Greedy que implementamos, en promedio, tiene mejor rendimiento que el algoritmo por aproximación Bilardo. Tanto en los tiempos de ejecución como hallando soluciones más próximas a la óptima.

Con grandes sets de datos, obtener la solución óptima requiere aumentar los tiempos de ejecución, por lo cuál, puede ser preferible utilizar un algoritmo de aproximación sabiendo que puede no obtener una solución óptima. 

\end{document}

\documentclass{article}
\usepackage{amsmath}
